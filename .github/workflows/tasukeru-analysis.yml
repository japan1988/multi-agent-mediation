name: Auto-Tasukeru CI

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - "**/*.py"
      - "**/*.ipynb"
      - "pyproject.toml"
      - "requirements*.txt"
      - ".github/workflows/tasukeru-analysis.yml"
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write

concurrency:
  group: tasukeru-${{ github.event.pull_request.number || github.run_id }}
  cancel-in-progress: true

env:
  MAX_ZIP_MB: "10"
  MAX_FILES: "2000"
  INCLUDE_PATTERNS: |
    *.py
    *.ipynb
    pyproject.toml
    requirements*.txt

jobs:
  local-ci:
    runs-on: ubuntu-latest
    timeout-minutes: 8
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Prepare local CI deps (PyYAML optional)
        run: |
          python -m pip install --upgrade pip
          pip install PyYAML || true

      - name: Run offline CI
        run: |
          python local_ci.py --config ci_config.json || true

      - name: Attach offline summary
        if: always()
        run: |
          echo "### ðŸ§ª Local CI (offline)
          - See artifacts for results.csv / summary.md" >> "$GITHUB_STEP_SUMMARY"

      - name: Upload offline artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: local-ci-results
          path: |
            runs/**/results.csv
            runs/**/results.jsonl
            runs/**/summary.md

  analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [local-ci]
    if: ${{ github.event.pull_request.head.repo.fork == false }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Create source bundle (tracked + allowlist)
        id: bundle
        shell: bash
        run: |
          set -euo pipefail
          mapfile -t patterns < <(echo "${INCLUDE_PATTERNS}")
          include_args=()
          for p in "${patterns[@]}"; do
            [[ -z "$p" ]] && continue
            include_args+=( ":$p" )
          done
          git archive --format=zip -o source.zip HEAD -- "${include_args[@]}"
          files=$(zipinfo -1 source.zip | wc -l | tr -d ' ')
          bytes=$(stat -c%s source.zip || stat -f%z source.zip)
          mb=$(( (bytes + 1048575) / 1048576 ))
          echo "files=$files bytes=$bytes (~${mb}MB)"
          if [ "$files" -gt "${MAX_FILES}" ]; then echo "Too many files: $files > ${MAX_FILES}"; exit 1; fi
          if [ "$mb" -gt "${MAX_ZIP_MB}" ]; then echo "Archive too large: ${mb}MB > ${MAX_ZIP_MB}MB"; exit 1; fi
          (command -v sha256sum >/dev/null && sha256sum source.zip) || shasum -a 256 source.zip

      - name: Strip notebook outputs (optional)
        if: ${{ hashFiles('**/*.ipynb') != '' }}
        run: |
          python - <<'PY'
          import json, zipfile, io
          z_in = zipfile.ZipFile('source.zip','r')
          buf = io.BytesIO()
          z_out = zipfile.ZipFile(buf,'w',zipfile.ZIP_DEFLATED)
          for info in z_in.infolist():
            data = z_in.read(info.filename)
            if info.filename.endswith(".ipynb"):
              try:
                nb = json.loads(data.decode("utf-8"))
                for cell in nb.get("cells", []):
                  if cell.get("outputs"): cell["outputs"] = []
                  if "execution_count" in cell: cell["execution_count"] = None
                data = json.dumps(nb, ensure_ascii=False).encode("utf-8")
              except Exception:
                pass
            z_out.writestr(info, data)
          z_out.close()
          open('source.zip','wb').write(buf.getvalue())
          PY

      - name: Ensure secrets exist (skip if missing)
        id: have_secrets
        shell: bash
        run: |
          if [ -z "${{ secrets.TASUKERU_URL }}" ] || [ -z "${{ secrets.TASUKERU_TOKEN }}" ]; then
            echo "has=false" >> $GITHUB_OUTPUT
          else
            echo "has=true" >> $GITHUB_OUTPUT
          fi

      - name: Call Tasukeru API
        if: ${{ steps.have_secrets.outputs.has == 'true' }}
        env:
          TASUKERU_URL: ${{ secrets.TASUKERU_URL }}
          TASUKERU_TOKEN: ${{ secrets.TASUKERU_TOKEN }}
        run: |
          set -euo pipefail
          for i in 1 2 3; do
            curl --fail-with-body --show-error --silent \
                 --max-time 30 \
                 -X POST "$TASUKERU_URL" \
                 -H "Authorization: Bearer $TASUKERU_TOKEN" \
                 -H "X-Repo:${{ github.repository }}" \
                 -H "X-PR:${{ github.event.pull_request.number }}" \
                 -F "file=@source.zip" \
                 -o report.md && break || sleep 3
          done
          test -s report.md

      - name: Post report as PR comment
        if: ${{ steps.have_secrets.outputs.has == 'true' && github.event_name == 'pull_request' }}
        uses: peter-evans/create-or-update-comment@v4
        with:
          issue-number: ${{ github.event.pull_request.number }}
          body-path: report.md

      - name: Upload report artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: tasukeru-report
          path: |
            report.md
            source.zip

  dry-run:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    if: ${{ github.event.pull_request.head.repo.fork == true }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Fork policy notice
        shell: bash
        run: echo "Fork PR: external analysis is skipped by policy."
