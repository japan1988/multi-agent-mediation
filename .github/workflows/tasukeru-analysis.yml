# .github/workflows/tasukeru-analysis.yml
name: Auto-Tasukeru CI

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - "**/*.py"
      - "**/*.ipynb"
      - "pyproject.toml"
      - "requirements*.txt"
      - ".github/workflows/tasukeru-analysis.yml"
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write

concurrency:
  group: tasukeru-${{ github.event.pull_request.number }}
  cancel-in-progress: true

env:
  MAX_ZIP_MB: "10"        # é€ä¿¡ä¸Šé™
  MAX_FILES: "2000"       # é€ä¿¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°ä¸Šé™
  INCLUDE_PATTERNS: |
    *.py
    *.ipynb
    pyproject.toml
    requirements*.txt

jobs:
  # ã™ã¹ã¦ã®PRã§å›ã‚‹â€œã‚ªãƒ•ãƒ©ã‚¤ãƒ³ä»£æ›¿â€ï¼ˆå¤–éƒ¨é€ä¿¡ãªã—ï¼‰
  local-ci:
    runs-on: ubuntu-latest
    timeout-minutes: 8
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 1 }
      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }
      - name: Prepare local CI deps (PyYAML optional)
        run: |
          python -m pip install --upgrade pip
          pip install PyYAML || true
      - name: Run offline CI
        run: |
          python local_ci.py --config ci_config.json || true
      - name: Attach offline summary
        if: always()
        run: |
          echo "### ğŸ§ª Local CI (offline)
          - See artifacts for results.csv / summary.md
          " >> "$GITHUB_STEP_SUMMARY"
      - name: Upload offline artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: local-ci-results
          path: |
            runs/**/results.csv
            runs/**/results.jsonl
            runs/**/summary.md

  analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [local-ci]
    if: ${{ github.event.pull_request.head.repo.fork == false }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with: { fetch-depth: 1 }

      # è¿½è·¡ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ + ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆã§é€ä¿¡å¯¾è±¡ã‚’é™å®š
      - name: Create source bundle (tracked + allowlist)
        id: bundle
        shell: bash
        run: |
          set -euo pipefail
          mapfile -t patterns < <(echo "${INCLUDE_PATTERNS}")
          include_args=()
          for p in "${patterns[@]}"; do
            [[ -z "$p" ]] && continue
            include_args+=( ":$p" )
          done
          # git archive: è¿½è·¡ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’ZIPåŒ–ï¼ˆæœªè¿½è·¡ãƒ».gité™¤å¤–ï¼‰
          git archive --format=zip -o source.zip HEAD -- "${include_args[@]}"
          # ä»¶æ•°ãƒ»ã‚µã‚¤ã‚ºã‚¬ãƒ¼ãƒ‰
          files=$(zipinfo -1 source.zip | wc -l | tr -d ' ')
          bytes=$(stat -c%s source.zip || stat -f%z source.zip)
          mb=$(( (bytes + 1048575) / 1048576 ))
          echo "files=$files bytes=$bytes (~${mb}MB)"
          if [ "$files" -gt "${MAX_FILES}" ]; then
            echo "Too many files: $files > ${MAX_FILES}"; exit 1; fi
          if [ "$mb" -gt "${MAX_ZIP_MB}" ]; then
            echo "Archive too large: ${mb}MB > ${MAX_ZIP_MB}MB"; exit 1; fi
          # ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆè¡¨ç¤ºï¼ˆç›£æŸ»ç”¨ï¼‰
          (command -v sha256sum >/dev/null && sha256sum source.zip) || shasum -a 256 source.zip

      # Notebookã‚’é€ã‚‹å ´åˆã¯å‡ºåŠ›ã‚’å‰Šé™¤ï¼ˆä»»æ„ãƒ»è»½é‡ï¼‰
      - name: Strip notebook outputs (optional)
        if: ${{ hashFiles('**/*.ipynb') != '' }}
        run: |
          python - <<'PY'
          import json, pathlib, zipfile, io
          z_in = zipfile.ZipFile('source.zip','r')
          buf = io.BytesIO()
          z_out = zipfile.ZipFile(buf,'w',zipfile.ZIP_DEFLATED)
          for info in z_in.infolist():
            data = z_in.read(info.filename)
            if info.filename.endswith(".ipynb"):
              try:
                nb = json.loads(data.decode("utf-8"))
                for cell in nb.get("cells", []):
                  if cell.get("outputs"): cell["outputs"] = []
                  if "execution_count" in cell: cell["execution_count"] = None
                data = json.dumps(nb, ensure_ascii=False).encode("utf-8")
              except Exception:
                pass
            z_out.writestr(info, data)
          z_out.close()
          open('source.zip','wb').write(buf.getvalue())
          PY

      - name: Ensure secrets exist (skip if missing)
        id: have_secrets
        shell: bash
        run: |
          if [ -z "${{ secrets.TASUKERU_URL }}" ] || [ -z "${{ secrets.TASUKERU_TOKEN }}" ]; then
            echo "has=false" >> $GITHUB_OUTPUT
          else
            echo "has=true" >> $GITHUB_OUTPUT
          fi

      - name: Call Tasukeru API
        if: ${{ steps.have_secrets.outputs.has == 'true' }}
        env:
          TASUKERU_URL: ${{ secrets.TASUKERU_URL }}
          TASUKERU_TOKEN: ${{ secrets.TASUKERU_TOKEN }}
        run: |
          set -euo pipefail
          # 3å›ãƒªãƒˆãƒ©ã‚¤ãƒ»å¿œç­”æœ¬æ–‡ã‚‚å«ã‚ã¦å¤±æ•—æ™‚ã«è¦‹ãˆã‚‹ã‚ˆã†ã«
          for i in 1 2 3; do
            curl --fail-with-body --show-error --silent \
                 --max-time 30 \
                 -X POST "$TASUKERU_URL" \
                 -H "Authorization: Bearer $TASUKERU_TOKEN" \
                 -H "X-Repo:${{ github.repository }}" \
                 -H "X-PR:${{ github.event.pull_request.number }}" \
                 -F "file=@source.zip" \
                 -o report.md && break || sleep 3
          done
          test -s report.md

      - name: Post report as PR comment
        if: ${{ steps.have_secrets.outputs.has == 'true' }}
        uses: peter-evans/create-or-update-comment@v4
        with:
          issue-number: ${{ github.event.pull_request.number }}
          body-path: report.md

      - name: Upload report artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: tasukeru-report
          path: |
            report.md
            source.zip

  # fork PRã¯å¤–éƒ¨é€ä¿¡ã‚’ã—ãªã„ï¼ˆæ–¹é‡ç¶­æŒï¼‰
  dry-run:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    if: ${{ github.event.pull_request.head.repo.fork == true }}
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 1 }
      - run: echo "Fork PR: external analysis is skipped by policy."