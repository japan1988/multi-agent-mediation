

---

**Technical Background**

This project aims to develop a simulator that facilitates smooth negotiation and mediation among multiple AI agents with differing values and priorities.
It reproduces the processes of adjusting diverse interests and forming compromises—tasks that are challenging for single AI control—through dynamic alliance formation and intervention by a mediator AI.

The system is designed with reference to international governance standards, enabling verification of mediation processes from the perspectives of safety and fairness.
As a result, it is expected to have broad applications, including research and education on collective AI decision-making, as well as practical support for consensus-building in real-world scenarios.

---

**Package Contents**

* Main notebook: Untitled27 (3).ipynb and others
* Sample Python code set
* Documentation and design explanation materials
* Disclaimer

---

**Disclaimer**

This package is released solely for educational and research purposes.
The author assumes no responsibility for any damages or issues arising from the use or application of this package.
Use, modification, and redistribution are at your own risk.

International AI ethics guidelines (OECD, EU, IEEE, etc.) are referenced, but full compliance or absolute safety is NOT guaranteed.
Commercial use is strictly prohibited.
Malicious or illegal use of this package is strictly forbidden.

The author assumes no responsibility for any privacy or copyright issues arising from the use of this package.

---



