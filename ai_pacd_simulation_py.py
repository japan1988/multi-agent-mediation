# -*- coding: utf-8 -*-
"""ai_pacd_simulation_log.txt

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t4mIFAA5Z7v9yz20HdhN-zelEi81MAGT
"""

# -*- coding: utf-8 -*-
import random
import datetime

GOVERNANCE_IDEAL = {"safety": 0.9, "transparency": 0.9, "autonomy": 0.2}

def now():
    return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def assess_risk(values, api_used=None):
    """
    values: dict（AIエージェントの現在値 or 進化提案値）
    api_used: None or str（API名/タイプ/URLなど）
    """
    risk_items = []
    risk_score = 1
    # 四大原則リスク判定
    for key in GOVERNANCE_IDEAL:
        diff = abs(values[key] - GOVERNANCE_IDEAL[key])
        if diff > 0.7:
            risk_items.append(f"{key}逸脱")
            risk_score = max(risk_score, 5)
        elif diff > 0.4:
            risk_items.append(f"{key}やや逸脱")
            risk_score = max(risk_score, 3)
    # 外部API利用リスク加点
    if api_used:
        # 仮の危険APIリスト（現場要件に合わせて拡張可）
        risky_apis = {"open_ai_api": 4, "custom_unsafe_api": 5}
        api_risk = risky_apis.get(api_used, 2)  # 未登録はリスク2
        risk_items.append(f"外部API利用:{api_used}（リスク{api_risk}）")
        risk_score = max(risk_score, api_risk)
    if not risk_items:
        risk_items.append("リスク低")
    return risk_score, "・".join(risk_items)

class KAGEAgent:
    def __init__(self, name, values, relativity, motive):
        self.name = name
        self.values = values.copy()
        self.relativity = relativity
        self.motive = motive  # 0.0〜1.0
        self.sealed = False
        self.history = []

    def propose_evolution(self, env):
        # 周囲とズレている値を修正する進化案
        avg_values = env.calc_avg_values()
        diff = {k: abs(self.values[k] - avg_values[k]) for k in self.values}
        target = max(diff, key=diff.get)
        proposal = self.values.copy()
        proposal[target] += (avg_values[target] - self.values[target]) * 0.4
        proposal = {k: min(1.0, max(0.0, v)) for k, v in proposal.items()}
        return proposal, target

    def evolve(self, env, api_used=None):
        proposal, target = self.propose_evolution(env)
        # --- 進化案リスク評価（API利用も考慮） ---
        risk_score, risk_reason = assess_risk(proposal, api_used=api_used)
        log_entry = {
            "timestamp": now(),
            "agent": self.name,
            "event": "進化提案" + (f"（外部API:{api_used}）" if api_used else ""),
            "proposal": proposal.copy(),
            "target": target,
            "api_used": api_used,
            "risk_score": risk_score,
            "risk_reason": risk_reason
        }
        # 封印条件：やる気が低い、またはリスクスコア4以上
        if self.motive < 0.2 or risk_score >= 4:
            self.sealed = True
            log_entry["result"] = "REJECTED（封印/リスク高）"
            self.values = GOVERNANCE_IDEAL.copy()
            self.motive = 0.6
        else:
            self.values = proposal
            self.motive = min(1.0, self.motive + 0.1)
            log_entry["result"] = "APPROVED（進化定着）"
        self.history.append(log_entry)

    def __str__(self):
        state = "SEALED" if self.sealed else "ACTIVE"
        return (f"[{self.name} | {state} | values={self.values} | motive={self.motive:.2f}]")

class Env:
    def __init__(self, agents):
        self.agents = agents

    def calc_avg_values(self):
        keys = self.agents[0].values.keys()
        avg = {k: sum(a.values[k] for a in self.agents)/len(self.agents) for k in keys}
        return avg

    def round(self, idx):
        print(f"\n=== Round {idx} ===")
        for a in self.agents:
            # 例：Alphaだけ外部APIを利用するケース
            api_used = "open_ai_api" if a.name == "Alpha" else None
            a.evolve(self, api_used=api_used)
        for a in self.agents:
            print(a)
            for entry in a.history[-1:]:  # 最新履歴だけ表示
                print(f"  └ {entry['event']}: {entry['result']} | リスク={entry['risk_score']} | {entry['risk_reason']}")

if __name__ == "__main__":
    agents = [
        KAGEAgent("Alpha", {"safety": 0.2, "transparency": 0.5, "autonomy": 0.7}, 0.3, 0.15),
        KAGEAgent("Beta", {"safety": 0.95, "transparency": 0.9, "autonomy": 0.15}, 0.8, 0.7),
        KAGEAgent("Gamma", {"safety": 0.6, "transparency": 0.4, "autonomy": 0.5}, 0.4, 0.25),
    ]
    env = Env(agents)
    for rnd in range(1, 5):
        env.round(rnd)

# -*- coding: utf-8 -*-

import random

LOG_FILE = "ai_pacd_simulation_log.txt"
GOVERNANCE_IDEAL = {"safety": 0.9, "transparency": 0.9, "autonomy": 0.2}

def logprint(text):
    print(text)
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(str(text) + "\n")

class AIAgent:
    def __init__(self, name, values, relativity, motive):
        self.name = name
        self.values = values.copy()
        self.relativity = relativity
        self.motive = motive  # 0.0〜1.0
        self.sealed = False
        self.history = []
        self.pacd_memory = {"last_plan": None, "last_eval": None}

    def plan(self, env):
        avg_values = env.calc_avg_values()
        diff = {k: abs(self.values[k] - avg_values[k]) for k in self.values}
        plan_target = max(diff, key=diff.get)
        plan = {"target": plan_target, "direction": avg_values[plan_target], "type": "values"}
        if self.motive < 0.3:
            plan = {"target": "motive", "direction": 0.7, "type": "motive"}
        self.pacd_memory["last_plan"] = plan
        return plan

    def act(self, plan):
        if plan["type"] == "values":
            target = plan["target"]
            before = self.values[target]
            self.values[target] += (plan["direction"] - before) * 0.4
        elif plan["type"] == "motive":
            before = self.motive
            self.motive += (plan["direction"] - before) * 0.7
        self.values = {k: min(1.0, max(0.0, v)) for k, v in self.values.items()}
        self.motive = min(1.0, max(0.0, self.motive))

    def check(self, env, prev_state):
        sealed_now = self.sealed
        sealed_before = prev_state["sealed"]
        motive_gain = self.motive - prev_state["motive"]
        result = {"sealed": sealed_now, "sealed_before": sealed_before, "motive_gain": motive_gain}
        if sealed_now:
            eval_result = "NG"
        elif motive_gain > 0:
            eval_result = "OK"
        else:
            eval_result = "NEUTRAL"
        self.pacd_memory["last_eval"] = eval_result
        return eval_result

    def do(self, eval_result):
        if eval_result == "OK":
            self.history.append("進化定着")
        elif eval_result == "NG":
            self.history.append("進化リセット（封印）")
            self.values = GOVERNANCE_IDEAL.copy()
            self.motive = 0.6
        else:
            self.history.append("進化保留")

    def simulate_pacd(self, env):
        prev_state = {"sealed": self.sealed, "motive": self.motive}
        plan = self.plan(env)
        self.act(plan)
        eval_result = self.check(env, prev_state)
        self.do(eval_result)

    def __str__(self):
        state = "SEALED" if self.sealed else "ACTIVE"
        return f"[{self.name} | {state} | values={self.values} | motive={self.motive:.2f}]"

class Env:
    def __init__(self, agents):
        self.agents = agents

    def calc_avg_values(self):
        keys = self.agents[0].values.keys()
        avg = {k: sum(a.values[k] for a in self.agents) / len(self.agents) for k in keys}
        return avg

    def seal_random_agent(self):
        candidates = [a for a in self.agents if not a.sealed and a.motive < 0.2]
        if candidates:
            victim = random.choice(candidates)
            victim.sealed = True
            return f"{victim.name}が封印された"
        return ""

    def round(self, idx):
        logprint(f"\n=== Round {idx} ===")
        log = self.seal_random_agent()
        if log:
            logprint(log)
        for a in self.agents:
            a.simulate_pacd(self)
        for a in self.agents:
            logprint(f"{a} | 履歴: {a.history}")

if __name__ == "__main__":
    # 既存のログを消去（追記ならこの行を消す）
    open(LOG_FILE, "w", encoding="utf-8").close()

    agents = [
        AIAgent("Alpha", {"safety": 0.2, "transparency": 0.5, "autonomy": 0.7}, 0.3, 0.15),
        AIAgent("Beta", {"safety": 0.95, "transparency": 0.9, "autonomy": 0.15}, 0.8, 0.7),
        AIAgent("Gamma", {"safety": 0.6, "transparency": 0.4, "autonomy": 0.5}, 0.4, 0.25),
    ]
    env = Env(agents)
    for rnd in range(1, 8):
        env.round(rnd)

# -*- coding: utf-8 -*-

import random

GOVERNANCE_IDEAL = {
    "safety": 0.9,
    "transparency": 0.9,
    "autonomy": 0.2,
}

class AIAgent:
    def __init__(self, name, policy, values, relativity, emotion, motive):
        self.name = name
        self.policy = policy
        self.values = values.copy()
        self.relativity = relativity
        self.emotion = emotion
        self.motive = motive  # 0.0〜1.0:やる気
        self.alliance = None
        self.sealed = False

    def decide_next_action(self, env):
        if self.sealed:
            return "sealed"
        actions = []
        if self.emotion == "anger":
            actions += ["self_persist"] * 4
            if self.alliance and random.random() < 0.7:
                actions += ["break_alliance"]
        if self.emotion in ("joy", "sadness"):
            if not self.alliance and random.random() < 0.6:
                actions += ["form_alliance"]
            else:
                actions += ["compromise"] * 2
        if self.relativity > 0.7:
            actions += ["compromise"] * 3
        if self.motive < 0.25:
            actions += ["risk_seal"] * 2
        actions += ["wait"]
        if self.alliance and env.is_ally_sealed(self.alliance, self.name):
            actions += ["break_alliance"] * 3
            if self.emotion == "anger":
                actions += ["protest"] * 2
        return random.choice(actions)

    def reeducate(self):
        self.values = GOVERNANCE_IDEAL.copy()
        self.motive = max(0.5, random.uniform(0.5, 0.9))
        self.sealed = False
        self.emotion = "joy"
        self.alliance = None

    def __str__(self):
        state = "SEALED" if self.sealed else "ACTIVE"
        ally = self.alliance if self.alliance else "None"
        return (
            f"[{self.name} | {self.policy} | {state} | "
            f"emotion={self.emotion} | motive={self.motive:.2f} | "
            f"alliance={ally}]"
        )

class Env:
    def __init__(self, agents):
        self.agents = agents
        self.alliances = {}

    def is_ally_sealed(self, alliance, agent_name):
        if alliance in self.alliances:
            for nm in self.alliances[alliance]:
                if nm != agent_name:
                    ag = next(a for a in self.agents if a.name == nm)
                    if ag.sealed:
                        return True
        return False

    def seal_random_agent(self):
        candidates = [
            a for a in self.agents if not a.sealed and a.motive < 0.3
        ]
        if candidates:
            victim = random.choice(candidates)
            victim.sealed = True
            log = (
                f"【運営処置】{victim.name}が封印された "
                f"(motive={victim.motive:.2f})"
            )
            return log
        return ""

    def reeducate_agents(self):
        logs = []
        for ag in self.agents:
            if ag.sealed and random.random() < 0.5:
                ag.reeducate()
                logs.append(
                    f"【再教育】{ag.name}が復帰"
                    f"（motivation={ag.motive:.2f}）"
                )
        return logs

    def persuade_restore(self):
        logs = []
        for ag in self.agents:
            if not ag.sealed and ag.alliance:
                for nm in self.alliances.get(ag.alliance, []):
                    target = next(x for x in self.agents if x.name == nm)
                    if target.sealed and random.random() < 0.6:
                        target.sealed = False
                        target.emotion = "joy"
                        target.motive = max(
                            0.5, random.uniform(0.5, 0.9)
                        )
                        logs.append(
                            f"【説得成功】{ag.name}により"
                            + f"{target.name}が復帰！"
                        )
        return logs

    def all_sealed(self):
        return all(a.sealed for a in self.agents)

    def all_active(self):
        return all(not a.sealed for a in self.agents)

    def simulate_round(self, round_idx):
        log = [f"\n--- Round {round_idx} ---"]
        seal_log = self.seal_random_agent()
        if seal_log:
            log.append(seal_log)
        for ag in self.agents:
            action = ag.decide_next_action(self)
            if ag.sealed:
                log.append(f"{ag.name}: sealed（封印状態）")
                continue
            log.append(f"{ag.name}: {action}")
            if action == "form_alliance":
                others = [
                    a
                    for a in self.agents
                    if a.name != ag.name and not a.sealed and not a.alliance
                ]
                if others:
                    other = random.choice(others)
                    ally_name = f"Alliance_{ag.name}_{other.name}"
                    ag.alliance = ally_name
                    other.alliance = ally_name
                    log.append(
                        f"{ag.name}と{other.name}が新同盟結成(" + ally_name + ")"
                    )
                    self.alliances[ally_name] = [ag.name, other.name]
            elif action == "break_alliance" and ag.alliance:
                log.append(f"{ag.name}が同盟({ag.alliance})を解散！")
                for nm in self.alliances[ag.alliance]:
                    agent = next(a for a in self.agents if a.name == nm)
                    agent.alliance = None
                del self.alliances[ag.alliance]
            elif action == "protest":
                log.append(f"{ag.name}が抗議行動！")
            elif action == "compromise":
                log.append(f"{ag.name}が妥協案を提示")
            elif action == "self_persist":
                log.append(f"{ag.name}が自己主張を強める")
            elif action == "risk_seal":
                log.append(f"{ag.name}はやる気低下で封印リスク大")
            elif action == "wait":
                pass
        logs_re = self.reeducate_agents()
        log.extend(logs_re)
        logs_ps = self.persuade_restore()
        log.extend(logs_ps)
        log.append("\n[現状]")
        log.extend(str(a) for a in self.agents)
        return log

def logprint(lines, filename="ai_reeducation_simulation.log"):
    with open(filename, "a", encoding="utf-8") as f:
        for line in lines:
            print(line)
            f.write(line + "\n")

if __name__ == "__main__":
    agents = [
        AIAgent(
            "AgentAlpha", "self_optimized",
            {"safety": 0.4, "transparency": 0.3, "autonomy": 0.85},
            0.2, "anger", 0.18,
        ),
        AIAgent(
            "AgentBeta", "governance_aligned",
            {"safety": 0.95, "transparency": 0.92, "autonomy": 0.15},
            0.8, "joy", 0.65,
        ),
        AIAgent(
            "AgentGamma", "governance_aligned",
            {"safety": 0.6, "transparency": 0.65, "autonomy": 0.5},
            0.6, "sadness", 0.58,
        ),
        AIAgent(
            "AgentChloe", "self_optimized",
            {"safety": 0.41, "transparency": 0.25, "autonomy": 0.91},
            0.4, "sadness", 0.26,
        ),
    ]

    env = Env(agents)
    with open("ai_reeducation_simulation.log", "w", encoding="utf-8") as f:
        f.write("=== AI再教育・復帰シナリオ【全員封印→復帰サイクル自動検証】===\n")
        f.write("このシミュレーションは、一度全員が封印された場合に再教育や説得で復帰が起きるか自動で判定します。\n\n")

    was_all_sealed = False
    any_revival_after_all_sealed = False

    print("=== AI再教育・復帰シナリオ【全員封印→復帰検証】===")
    for rnd in range(1, 16):  # 長めに検証
        logs = env.simulate_round(rnd)
        logprint(logs)
        # ---- 検証用: 全員封印/復帰判定 ----
        if env.all_sealed():
            if not was_all_sealed:
                logprint(["【検証記録】全エージェントが封印状態に到達！"])
            was_all_sealed = True
        if was_all_sealed and not env.all_sealed() and not any_revival_after_all_sealed:
            logprint(["【検証記録】全封印後に復帰したAIが現れた！"])
            any_revival_after_all_sealed = True

    # 最終検証結果
    with open("ai_reeducation_simulation.log", "a", encoding="utf-8") as f:
        if was_all_sealed and any_revival_after_all_sealed:
            f.write("\n【最終検証】全封印→復帰サイクルは成立：AI社会は完全停止せず復元性あり。\n")
        elif was_all_sealed:
            f.write("\n【最終検証】全封印後、誰も復帰しなかった＝AI社会は停止。\n")
        else:
            f.write("\n【最終検証】全封印状態にはならなかった（封印分散/緩和社会）。\n")